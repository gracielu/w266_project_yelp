{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC MODELING\n",
    "Latent Dirichlet Allocation (LDA)\n",
    "The LDA is based upon two general assumptions:\n",
    "\n",
    "-Documents that have similar words usually have the same topic\n",
    "-Documents that have groups of words frequently occurring together usually have the same topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asian       50000\n",
       "American    50000\n",
       "Mexican     50000\n",
       "Name: cuisine, dtype: int64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews=pd.read_csv(\"./review_data.csv\",usecols=[\"useful\",\"text\", \"cuisine\"])\n",
    "reviews=reviews.groupby('cuisine').apply(lambda s: s.sample(50000))\n",
    "reviews[\"labels\"]= reviews[\"useful\"].apply(lambda x: 1 if x >= 1  else 0)\n",
    "reviews.cuisine.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuisine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Asian</th>\n",
       "      <th>1158252</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is an amazing deal for hibachi! Eac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25513</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>Good stuff here!!!  We've been going to Phoeni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53457</th>\n",
       "      <td>Asian</td>\n",
       "      <td>1</td>\n",
       "      <td>I got take out from here tonight and it was go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107523</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>My friend recommended Malee's one day for lunc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330831</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>I wasn't sure what I was expecting, but wow! W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cuisine  useful  \\\n",
       "cuisine                           \n",
       "Asian   1158252   Asian       0   \n",
       "        25513     Asian       0   \n",
       "        53457     Asian       1   \n",
       "        107523    Asian       0   \n",
       "        330831    Asian       0   \n",
       "\n",
       "                                                              text  labels  \n",
       "cuisine                                                                     \n",
       "Asian   1158252  This place is an amazing deal for hibachi! Eac...       0  \n",
       "        25513    Good stuff here!!!  We've been going to Phoeni...       0  \n",
       "        53457    I got take out from here tonight and it was go...       1  \n",
       "        107523   My friend recommended Malee's one day for lunc...       0  \n",
       "        330831   I wasn't sure what I was expecting, but wow! W...       0  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_datasets = reviews\n",
    "reviews_datasets = reviews[reviews.cuisine == \"Asian\"]\n",
    "# reviews_datasets = reviews_datasets[reviews_datasets.labels == 1]\n",
    "reviews_datasets.dropna()\n",
    "reviews_datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')  \n",
    "doc_term_matrix = count_vect.fit_transform(reviews_datasets['text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=3, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=3, random_state=42)  \n",
    "LDA.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talkative\n",
      "eyebrows\n",
      "tells\n",
      "chai\n",
      "molded\n",
      "seaside\n",
      "blinded\n",
      "barbeque\n",
      "redecorating\n",
      "chaffing\n"
     ]
    }
   ],
   "source": [
    "#Fetching words randomly to check that the words are present in the vocabulary\n",
    "import random\n",
    "\n",
    "for i in range(10):  \n",
    "    random_id = random.randint(0,len(count_vect.get_feature_names()))\n",
    "    print(count_vect.get_feature_names()[random_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find top 20 words with highest probability of 5 topics\n",
    "first_topic = LDA.components_[0]  \n",
    "second_topic = LDA.components_[1]\n",
    "third_topic = LDA.components_[2] \n",
    "# fourth_topic = LDA.components_[3]\n",
    "# fifth_topic = LDA.components_[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the index according to probability\n",
    "\n",
    "top_topic_words_first = first_topic.argsort()[-20:] \n",
    "top_topic_words_second = second_topic.argsort()[-20:]  \n",
    "top_topic_words_third = third_topic.argsort()[-20:]  \n",
    "# top_topic_words_fourth = fourth_topic.argsort()[-20:]  \n",
    "# top_topic_words_fifth = fifth_topic.argsort()[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11010,   952, 14001,  4844, 10241,  7213, 14114,  8611,  1908,\n",
       "       10481,  7191, 14864,  8143, 14857, 15555,  7017,  7689, 13101,\n",
       "        7839, 17299])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topic_words_first\n",
    "top_topic_words_second\n",
    "top_topic_words_third\n",
    "# top_topic_words_fourth\n",
    "# top_topic_words_fifth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_1 = []\n",
    "topic_2 = []\n",
    "topic_3 = []\n",
    "# topic_4 = []\n",
    "# topic_5 = []\n",
    "\n",
    "for i in range(0,20):  \n",
    "    topic_1.append(count_vect.get_feature_names()[top_topic_words_first[i]])\n",
    "    topic_2.append(count_vect.get_feature_names()[top_topic_words_second[i]])\n",
    "    topic_3.append(count_vect.get_feature_names()[top_topic_words_third[i]])\n",
    "#     topic_4.append(count_vect.get_feature_names()[top_topic_words_fourth[i]])\n",
    "#     topic_5.append(count_vect.get_feature_names()[top_topic_words_fifth[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>went</td>\n",
       "      <td>really</td>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>did</td>\n",
       "      <td>service</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asked</td>\n",
       "      <td>beef</td>\n",
       "      <td>ramen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>delicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>don</td>\n",
       "      <td>ve</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>said</td>\n",
       "      <td>just</td>\n",
       "      <td>friendly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>sauce</td>\n",
       "      <td>really</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>table</td>\n",
       "      <td>soup</td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ordered</td>\n",
       "      <td>ordered</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>got</td>\n",
       "      <td>fried</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>minutes</td>\n",
       "      <td>pho</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>came</td>\n",
       "      <td>chinese</td>\n",
       "      <td>rolls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>didn</td>\n",
       "      <td>great</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>place</td>\n",
       "      <td>like</td>\n",
       "      <td>roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>like</td>\n",
       "      <td>rice</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>service</td>\n",
       "      <td>thai</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>time</td>\n",
       "      <td>place</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>just</td>\n",
       "      <td>chicken</td>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>order</td>\n",
       "      <td>good</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>food</td>\n",
       "      <td>food</td>\n",
       "      <td>sushi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Topic 1     Topic 2    Topic 3\n",
       "0         went      really       menu\n",
       "1          did     service    amazing\n",
       "2        asked        beef      ramen\n",
       "3         good  restaurant  delicious\n",
       "4          don          ve       like\n",
       "5         said        just   friendly\n",
       "6   restaurant       sauce     really\n",
       "7        table        soup       hour\n",
       "8      ordered     ordered       best\n",
       "9          got       fried       love\n",
       "10     minutes         pho      fresh\n",
       "11        came     chinese      rolls\n",
       "12        didn       great      happy\n",
       "13       place        like       roll\n",
       "14        like        rice    service\n",
       "15     service        thai       food\n",
       "16        time       place       good\n",
       "17        just     chicken      place\n",
       "18       order        good      great\n",
       "19        food        food      sushi"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list(zip(topic_1, topic_2, topic_3)), \n",
    "               columns =['Topic 1', 'Topic 2', 'Topic 3']) \n",
    "# df = pd.DataFrame(list(zip(topic_1, topic_2, topic_3, topic_4, topic_5)), \n",
    "#                columns =['Topic 1', 'Topic 2', 'Topic 3', 'Topic 4', 'Topic 5']) \n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #1:\n",
      "['said', 'restaurant', 'table', 'ordered', 'got', 'minutes', 'came', 'didn', 'place', 'like', 'service', 'time', 'just', 'order', 'food']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['just', 'sauce', 'soup', 'ordered', 'fried', 'pho', 'chinese', 'great', 'like', 'rice', 'thai', 'place', 'chicken', 'good', 'food']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['friendly', 'really', 'hour', 'best', 'love', 'fresh', 'rolls', 'happy', 'roll', 'service', 'food', 'good', 'place', 'great', 'sushi']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Words with highest probabilties for all five topics\n",
    "for i,topic in enumerate(LDA.components_):  \n",
    "    print(f'Top 10 words for topic #{i+1}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suzychoi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuisine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Asian</th>\n",
       "      <th>1158252</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is an amazing deal for hibachi! Eac...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25513</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>Good stuff here!!!  We've been going to Phoeni...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53457</th>\n",
       "      <td>Asian</td>\n",
       "      <td>1</td>\n",
       "      <td>I got take out from here tonight and it was go...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107523</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>My friend recommended Malee's one day for lunc...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330831</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>I wasn't sure what I was expecting, but wow! W...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004316</th>\n",
       "      <td>Asian</td>\n",
       "      <td>1</td>\n",
       "      <td>This place is so good. I usually call ahead an...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924761</th>\n",
       "      <td>Asian</td>\n",
       "      <td>1</td>\n",
       "      <td>I just wanna talk about the employees here.  W...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308604</th>\n",
       "      <td>Asian</td>\n",
       "      <td>2</td>\n",
       "      <td>I\"m a fan, I like it I love it I'll eat more o...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890146</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>The only place you should buy potstickers! The...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078992</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>Third time and still amazing! Had egg rolls an...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cuisine  useful  \\\n",
       "cuisine                           \n",
       "Asian   1158252   Asian       0   \n",
       "        25513     Asian       0   \n",
       "        53457     Asian       1   \n",
       "        107523    Asian       0   \n",
       "        330831    Asian       0   \n",
       "        1004316   Asian       1   \n",
       "        924761    Asian       1   \n",
       "        308604    Asian       2   \n",
       "        890146    Asian       0   \n",
       "        1078992   Asian       0   \n",
       "\n",
       "                                                              text  labels  \\\n",
       "cuisine                                                                      \n",
       "Asian   1158252  This place is an amazing deal for hibachi! Eac...       0   \n",
       "        25513    Good stuff here!!!  We've been going to Phoeni...       0   \n",
       "        53457    I got take out from here tonight and it was go...       1   \n",
       "        107523   My friend recommended Malee's one day for lunc...       0   \n",
       "        330831   I wasn't sure what I was expecting, but wow! W...       0   \n",
       "        1004316  This place is so good. I usually call ahead an...       1   \n",
       "        924761   I just wanna talk about the employees here.  W...       1   \n",
       "        308604   I\"m a fan, I like it I love it I'll eat more o...       1   \n",
       "        890146   The only place you should buy potstickers! The...       0   \n",
       "        1078992  Third time and still amazing! Had egg rolls an...       0   \n",
       "\n",
       "                 Topic  \n",
       "cuisine                 \n",
       "Asian   1158252      3  \n",
       "        25513        2  \n",
       "        53457        2  \n",
       "        107523       2  \n",
       "        330831       3  \n",
       "        1004316      2  \n",
       "        924761       1  \n",
       "        308604       2  \n",
       "        890146       2  \n",
       "        1078992      2  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assign probability of all the topics to each document and adds a new column to show about which topic the review belongs\n",
    "topic_values = LDA.transform(doc_term_matrix)\n",
    "reviews_datasets['Topic'] = topic_values.argmax(axis=1)+1 \n",
    "reviews_datasets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic  labels\n",
       "1      0          5539\n",
       "       1          4916\n",
       "2      0         11309\n",
       "       1          9318\n",
       "3      0         11631\n",
       "       1          7287\n",
       "dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_datasets.groupby(['Topic','labels']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I wasn't sure what I was expecting, but wow! What a great price for so much food! I was surprised how fresh the fish I was. I wish this was here when I lived in Hassy... I would've been here everyday\""
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Topic 2: Service/Ambience\n",
    "reviews_datasets['text'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Topic 1: Service/Time\n",
    "reviews_datasets['Topic'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('asian_lda.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

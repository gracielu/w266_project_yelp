{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gracielu/w266_project_yelp/blob/master/Yelp_LSTM_Suzy_asian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XZkZiHHv-iI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "3gPCvp-WuZGC",
    "outputId": "9b3837e3-d304-4dc4-e038-113660d911b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBFfpek3v-iY"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hYV5wKCov-im"
   },
   "outputs": [],
   "source": [
    "yelp_reviews=pd.read_csv(\"./drive/My Drive/W266/review_data_asian.csv\",usecols=[\"useful\",\"text\", \"cuisine\"])\n",
    "# american_data = yelp_reviews[yelp_reviews['cuisine'] == 'American']\n",
    "# asian_data = yelp_reviews[yelp_reviews['cuisine'] == 'Asian']\n",
    "# mexican_data = yelp_reviews[yelp_reviews['cuisine'] == 'Mexican']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t5HeFEuXv-jG"
   },
   "outputs": [],
   "source": [
    "# yelp_reviews[yelp_reviews['cuisine'] == 'American'].to_csv('./review_data_american.csv',index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GM-QFmUOv-jK"
   },
   "outputs": [],
   "source": [
    "# yelp_reviews[yelp_reviews['cuisine'] == 'Asian'].to_csv('./drive/My Drive/W266/review_data_asian.csv',index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2k4iQdjEv-jN"
   },
   "outputs": [],
   "source": [
    "# yelp_reviews[yelp_reviews['cuisine'] == 'Mexican'].to_csv('/contents/My Drive/W266/review_data_mexican.csv',index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "Ety2fXOXv-i1",
    "outputId": "b071a1db-1002-40b6-9ae5-6eaf5bf405f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>We've tried a few different Chinese delivery p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian</td>\n",
       "      <td>6</td>\n",
       "      <td>My expectations of chinese delivery places in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asian</td>\n",
       "      <td>2</td>\n",
       "      <td>This place only gets one star because the syst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is exactly why I rarely eat Chinese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>I could only give this place a 3 out of 5.  Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Asian</td>\n",
       "      <td>3</td>\n",
       "      <td>This hole in the wall is more than meets the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Asian</td>\n",
       "      <td>2</td>\n",
       "      <td>Ok, 4 stars because of the food alone on this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Asian</td>\n",
       "      <td>1</td>\n",
       "      <td>Possibly the worst chinese I've ever had. Very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>For Chinese take out food, this is my place. O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>Really REALLY bad food! This is NOT a good chi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cuisine  useful                                               text\n",
       "0   Asian       0  We've tried a few different Chinese delivery p...\n",
       "1   Asian       6  My expectations of chinese delivery places in ...\n",
       "2   Asian       2  This place only gets one star because the syst...\n",
       "3   Asian       0  This place is exactly why I rarely eat Chinese...\n",
       "4   Asian       0  I could only give this place a 3 out of 5.  Th...\n",
       "5   Asian       3  This hole in the wall is more than meets the e...\n",
       "6   Asian       2  Ok, 4 stars because of the food alone on this ...\n",
       "7   Asian       1  Possibly the worst chinese I've ever had. Very...\n",
       "8   Asian       0  For Chinese take out food, this is my place. O...\n",
       "9   Asian       0  Really REALLY bad food! This is NOT a good chi..."
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "OJ2E8sDpv-jA",
    "outputId": "6b6eb98d-0d7a-4f9d-ac26-6adfc48d8dc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asian    203189\n",
       "Name: cuisine, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews['cuisine'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "qYLbxleHv-jR",
    "outputId": "3d5e21a5-36e5-404e-fa2b-c9f05aa24dd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     115926\n",
       "1      44747\n",
       "2      19069\n",
       "3       9158\n",
       "4       4833\n",
       "       ...  \n",
       "88         1\n",
       "89         1\n",
       "90         1\n",
       "91         1\n",
       "84         1\n",
       "Name: useful, Length: 119, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews['useful'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "WhPW99_Nv-jW",
    "outputId": "63700906-3460-42b1-b3dd-30f9d93b75a8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"This hole in the wall is more than meets the eye.  I''ve tried my luck at nearly every chinese takeout spot in the East Valley, and I can definitively say the food at China Gourmet impressed me the most.\\n\\nPROS: Made from scratch.  Heaping portions at very reasonable prices.  Quality far exceeds expectations.  Single-handedly raises the bar for local take-out.\\n\\nCONS:  Made from scratch.  So the wait time is fairly substantial (20-25 minutes in my case). Doesn't look like much from the outside.  Very small, only three tables and no restroom. Definitely intended to be a take-out only kind of place.\\n\\nRecommendation: \\nThe teriyaki beef was incredible, and not at all what I was expecting.  Instead of chopped beef in the thick teriyaki glaze I'm accustomed to, theirs was a thinner marinade that soaked completely through the meat.  Every piece was consistently tender and loaded with flavor.  I'd never had teriyaki of this caliber, and definitely didn't expect it from a little hole in the wall like this. Paid 8.95 for an order that could easily feed two with leftover.\\n\\nThe best, by far, was the hot and sour soup.  It put anything I'd tried previously to shame.  It was 2.50 for a quart, and short of Thai Chili's Tom Yum, it's the best hot and sour you'll find in the valley.  \\n\\nIf you happen to be in the area, it's definitely worth a shot.  Make time, so you can afford the wait, and you won't be disappointed.\""
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews.text[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "f6wUY7APv-ja",
    "outputId": "5904eacc-9c14-4aa7-d549-09724050ad86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuisine    False\n",
       "useful     False\n",
       "text       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AmB8jpw_v-jd"
   },
   "outputs": [],
   "source": [
    "yelp_reviews[\"labels\"]= yelp_reviews[\"useful\"].apply(lambda x: 1 if x >= 1  else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "P18vw-P5v-jg",
    "outputId": "2eacf2e3-6f65-4854-abbb-8b1f966bf8d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    115926\n",
       "1     87263\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "EIzrigUDv-jj",
    "outputId": "7fe44026-add7-4598-8971-120977488d74"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>We've tried a few different Chinese delivery p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian</td>\n",
       "      <td>6</td>\n",
       "      <td>My expectations of chinese delivery places in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asian</td>\n",
       "      <td>2</td>\n",
       "      <td>This place only gets one star because the syst...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is exactly why I rarely eat Chinese...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>I could only give this place a 3 out of 5.  Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Asian</td>\n",
       "      <td>3</td>\n",
       "      <td>This hole in the wall is more than meets the e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Asian</td>\n",
       "      <td>2</td>\n",
       "      <td>Ok, 4 stars because of the food alone on this ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Asian</td>\n",
       "      <td>1</td>\n",
       "      <td>Possibly the worst chinese I've ever had. Very...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>For Chinese take out food, this is my place. O...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>Really REALLY bad food! This is NOT a good chi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cuisine  useful                                               text  labels\n",
       "0   Asian       0  We've tried a few different Chinese delivery p...       0\n",
       "1   Asian       6  My expectations of chinese delivery places in ...       1\n",
       "2   Asian       2  This place only gets one star because the syst...       1\n",
       "3   Asian       0  This place is exactly why I rarely eat Chinese...       0\n",
       "4   Asian       0  I could only give this place a 3 out of 5.  Th...       0\n",
       "5   Asian       3  This hole in the wall is more than meets the e...       1\n",
       "6   Asian       2  Ok, 4 stars because of the food alone on this ...       1\n",
       "7   Asian       1  Possibly the worst chinese I've ever had. Very...       1\n",
       "8   Asian       0  For Chinese take out food, this is my place. O...       0\n",
       "9   Asian       0  Really REALLY bad food! This is NOT a good chi...       0"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "stop = stopwords.words('english')\n",
    "ps = PorterStemmer()\n",
    "\n",
    "reviews['text'] = reviews['text'].apply(lambda x: ' '.join([ps.stem(word) for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fo_SMfNBv-jn"
   },
   "outputs": [],
   "source": [
    "texts = yelp_reviews[\"text\"].values\n",
    "labels = yelp_reviews[\"labels\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mH6z_Yu1v-jq",
    "outputId": "f9c65968-0097-4d76-c973-176eae905742"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews[\"labels\"].values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "q2OXqWwtv-ju",
    "outputId": "8f2e1c4a-d8cc-46cb-aa68-ae4a47cd2182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203189,)\n",
      "(203189,)\n"
     ]
    }
   ],
   "source": [
    "print(texts.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "7BqDs7Idv-jz",
    "outputId": "09fbb430-b71a-4bda-b6de-5f61eb1d15d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 73129 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "vocab_size=10000\n",
    "max_len=500\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "nYJHkvbfv-j3",
    "outputId": "7ad424dd-f8c1-4b6e-9f35-49308d758d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[502, 152, 4, 192, 230, 108, 405, 195, 318, 1478, 100, 21, 4, 329, 471, 9, 108, 14, 16, 13, 22, 25, 68, 23, 14, 3, 41, 1, 134, 720, 498, 2, 713, 2949, 134, 1, 134, 6, 1515, 1561, 68, 86, 195, 12, 152, 8, 7, 71, 4, 23, 176, 17, 329, 259, 93, 62, 1, 6596, 6596, 1365, 228, 1027, 9, 1, 309, 11, 8, 28, 23]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "LFJdQrBSv-j6",
    "outputId": "16e23ef2-0cd2-4cba-96f8-ad4797d3cd67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 1)\n",
      "('schzwan', 73129)\n"
     ]
    }
   ],
   "source": [
    "print(list(word_index.items())[0])\n",
    "print(list(word_index.items())[73128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "RhInu4Opv-j9",
    "outputId": "12791e08-598d-4d8f-ddac-237dd622988d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(list(word_index.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlH6mprEv-kA"
   },
   "outputs": [],
   "source": [
    "data = sequence.pad_sequences(sequences, \n",
    "                              maxlen=max_len,\n",
    "                              padding='post', \n",
    "                              truncating='post'\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "4acugQi6v-kC",
    "outputId": "c5377fb1-378c-4eb4-e2a9-d2465c242cd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 502,  152,    4, ...,    0,    0,    0],\n",
       "       [  15, 1071,    9, ...,    0,    0,    0],\n",
       "       [  13,   22,   79, ...,    0,    0,    0],\n",
       "       [  13,   22,    7, ...,    0,    0,    0],\n",
       "       [   3,  138,   79, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "fSKRpMrYv-kF",
    "outputId": "8b08302b-fbd7-4714-f9ba-76d12d2cf51c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (203189, 500)\n",
      "Shape of label: (203189,)\n",
      "Shape of label: (203189, 2)\n"
     ]
    }
   ],
   "source": [
    "labels_b = to_categorical(np.asarray(labels))\n",
    "print('Shape of data:', data.shape)\n",
    "print('Shape of label:', labels.shape)\n",
    "print('Shape of label:', labels_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndqCRx6qv-kI"
   },
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "labels_b = labels_b[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "y_train_b = labels_b[:-nb_validation_samples]\n",
    "x_test = data[-nb_validation_samples:]\n",
    "y_test = labels[-nb_validation_samples:]\n",
    "y_test_b = labels_b[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "W7rYliwQv-kK",
    "outputId": "489a054a-12aa-40f7-cb0f-4747339df426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (162552, 500)\n",
      "Shape of x_test: (40637, 500)\n",
      "Shape of y_train: (162552,)\n",
      "Shape of y_train_b: (162552, 2)\n",
      "Shape of y_test: (40637,)\n",
      "Shape of y_test_b: (40637, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of x_train:', x_train.shape)\n",
    "print('Shape of x_test:', x_test.shape)\n",
    "print('Shape of y_train:', y_train.shape)\n",
    "print('Shape of y_train_b:', y_train_b.shape)\n",
    "print('Shape of y_test:', y_test.shape)\n",
    "print('Shape of y_test_b:', y_test_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "6gfklfO6v-kN",
    "outputId": "e79b3db8-0d4c-40c6-ec49-d0aa3b02e957"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  77    8    3 ...    0    0    0]\n",
      " [ 101  100  150 ...    0    0    0]\n",
      " [1129    5  296 ...    0    0    0]]\n",
      "[1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0:3])\n",
    "print(y_train[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nXqatziEv-kP"
   },
   "source": [
    "### Simple LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "4f_-Ox4Rv-kQ",
    "outputId": "4a066c85-4a52-434a-d96e-cf9fdd3af2d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 500)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_layer (Embedding)  (None, 500, 50)           500000    \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  (None, 256)               314368    \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 814,625\n",
      "Trainable params: 814,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Simple LSTM Classifier\n",
    "embedding_units = 50\n",
    "rnn_units = 256\n",
    "#attn_units=128\n",
    "\n",
    "#Simple LSTM Classifier\n",
    "sequence_input = layers.Input(shape=(max_len,),name=\"input_layer\", dtype='int32')\n",
    "embeddings = keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_units, input_length=max_len,name=\"embedding_layer\")(sequence_input)\n",
    "rnn_output=tf.keras.layers.LSTM(rnn_units,name='LSTM')(embeddings)\n",
    "output = keras.layers.Dense(1, activation='sigmoid',name='output_layer')(rnn_output)\n",
    "simple_model = keras.Model(inputs=sequence_input, outputs=output)\n",
    "\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qar5A0Kev-kT"
   },
   "outputs": [],
   "source": [
    "simple_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                        min_delta=0,\n",
    "                                                        patience=3,\n",
    "                                                        verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "UAMgPmm7v-kV",
    "outputId": "905f9528-41d7-4555-9da3-fa6c690f6a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "569/569 [==============================] - 165s 289ms/step - loss: 0.6855 - accuracy: 0.5743 - val_loss: 0.6823 - val_accuracy: 0.5743\n",
      "Epoch 2/10\n",
      "569/569 [==============================] - 163s 287ms/step - loss: 0.6808 - accuracy: 0.5760 - val_loss: 0.6812 - val_accuracy: 0.5748\n",
      "Epoch 3/10\n",
      "569/569 [==============================] - 166s 291ms/step - loss: 0.6804 - accuracy: 0.5755 - val_loss: 0.6812 - val_accuracy: 0.5746\n",
      "Epoch 4/10\n",
      "569/569 [==============================] - 166s 292ms/step - loss: 0.6799 - accuracy: 0.5763 - val_loss: 0.6817 - val_accuracy: 0.5743\n",
      "Epoch 5/10\n",
      "569/569 [==============================] - 166s 292ms/step - loss: 0.6793 - accuracy: 0.5764 - val_loss: 0.6811 - val_accuracy: 0.5742\n",
      "Epoch 6/10\n",
      "569/569 [==============================] - 166s 292ms/step - loss: 0.6791 - accuracy: 0.5768 - val_loss: 0.6817 - val_accuracy: 0.5746\n",
      "Epoch 7/10\n",
      "569/569 [==============================] - 166s 292ms/step - loss: 0.6785 - accuracy: 0.5771 - val_loss: 0.6829 - val_accuracy: 0.5743\n",
      "Epoch 8/10\n",
      "569/569 [==============================] - 165s 290ms/step - loss: 0.6812 - accuracy: 0.5765 - val_loss: 0.6814 - val_accuracy: 0.5742\n"
     ]
    }
   ],
   "source": [
    "history = simple_model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=200,\n",
    "                    validation_split=.3, verbose=1, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "x0fBdm8Jv-kX",
    "outputId": "42cf4c8b-c8c1-451a-b905-b3c61a1dab2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.29%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = simple_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9TUvX_7ov-kZ"
   },
   "source": [
    "### Bidirectional LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "GngpS8iMv-kc",
    "outputId": "c1faad92-fc3c-4498-cc84-a3e97d1736c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D,Conv1D\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "sequence_input = layers.Input(shape=(max_len,),name=\"input_layer\", dtype='int32')\n",
    "embeddings = keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_units, input_length=max_len,name=\"embedding_layer\")(sequence_input)\n",
    "x=Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(embeddings)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(2, activation=\"sigmoid\")(x)\n",
    "bidirectional_model = Model(inputs=sequence_input, outputs=x)\n",
    "bidirectional_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "fu7qgTx6v-kf",
    "outputId": "83f622ef-5884-42ad-e897-7466e448de7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "569/569 [==============================] - 2205s 4s/step - loss: 0.6428 - accuracy: 0.6353 - val_loss: 0.6329 - val_accuracy: 0.6425\n",
      "Epoch 2/5\n",
      "569/569 [==============================] - 2196s 4s/step - loss: 0.6213 - accuracy: 0.6602 - val_loss: 0.6298 - val_accuracy: 0.6483\n",
      "Epoch 3/5\n",
      "569/569 [==============================] - 2204s 4s/step - loss: 0.6053 - accuracy: 0.6758 - val_loss: 0.6386 - val_accuracy: 0.6447\n",
      "Epoch 4/5\n",
      "569/569 [==============================] - 2221s 4s/step - loss: 0.5863 - accuracy: 0.6918 - val_loss: 0.6491 - val_accuracy: 0.6409\n",
      "Epoch 5/5\n",
      "569/569 [==============================] - 2226s 4s/step - loss: 0.5644 - accuracy: 0.7110 - val_loss: 0.6620 - val_accuracy: 0.6309\n"
     ]
    }
   ],
   "source": [
    "bidirectional_model.fit(x_train, y_train_b, validation_split=.3,\n",
    "          epochs=5, batch_size=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Ldb6HhuAGINC",
    "outputId": "46f2c1fc-a596-42e5-f807-54da651abdc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.13%\n"
     ]
    }
   ],
   "source": [
    "scores = bidirectional_model.evaluate(x_test, y_test_b, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "METxMGE7v-kh"
   },
   "source": [
    "### LSTM Classifier with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6xRNOIAv-ki"
   },
   "outputs": [],
   "source": [
    "#our attention layer, uses Bahdanau Attention from 2015 paper that's essentially weighted sum, also known as \"additive attention\"\n",
    "class BahdanauAttention(layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        self._name=\"Attention\"\n",
    " \n",
    "    def call(self, features, hidden):\n",
    "    # hidden state shape == (batch_size, hidden size)\n",
    "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # values shape == (batch_size, max_len, hidden size)\n",
    "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "        \n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    " \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "nsOVvLufv-kk",
    "outputId": "9e02bc95-35e4-4841-da70-d671192367fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 500)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_layer (Embedding)  (None, 500, 50)           500000    \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  [(None, 500, 256), (None, 314368    \n",
      "_________________________________________________________________\n",
      "Attention (BahdanauAttention ((None, 256), (None, 500, 65921     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 880,546\n",
      "Trainable params: 880,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM Classifier with Attention\n",
    "attn_units=128\n",
    "\n",
    "sequence_input = layers.Input(shape=(max_len,),name=\"input_layer\", dtype='int32')\n",
    "embeddings = keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_units, input_length=max_len,name=\"embedding_layer\")(sequence_input)\n",
    "lstm_output,hidden_h, hidden_c=tf.keras.layers.LSTM(rnn_units,name='LSTM',return_sequences=True,\n",
    "                                      return_state=True)(embeddings)\n",
    "context_vector, attention_weights = BahdanauAttention(attn_units)(lstm_output, hidden_h)\n",
    "output = keras.layers.Dense(1, activation='sigmoid',name='output_layer')(context_vector)\n",
    "attn_model = keras.Model(inputs=sequence_input, outputs=output)\n",
    " \n",
    "# summarize layers\n",
    "attn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M__BtuGLv-kn"
   },
   "outputs": [],
   "source": [
    "attn_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                        min_delta=0,\n",
    "                                                        patience=3,\n",
    "                                                        verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "KAG9yZ7lv-kp",
    "outputId": "ca02882e-8f35-430d-8ef5-6f10d5076cbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "569/569 [==============================] - 85s 149ms/step - loss: 0.6381 - accuracy: 0.6398 - val_loss: 0.6321 - val_accuracy: 0.6528\n",
      "Epoch 2/2\n",
      "569/569 [==============================] - 84s 148ms/step - loss: 0.6215 - accuracy: 0.6586 - val_loss: 0.6303 - val_accuracy: 0.6491\n"
     ]
    }
   ],
   "source": [
    "history = attn_model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=2,\n",
    "                    batch_size=200,\n",
    "                    validation_split=.3, verbose=1, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "vTRlxhCev-kr",
    "outputId": "fe58996a-269c-421a-da60-430525d54e51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270/1270 [==============================] - 18s 15ms/step - loss: 0.6307 - accuracy: 0.6502\n",
      "[0.6307008266448975, 0.6502448320388794]\n"
     ]
    }
   ],
   "source": [
    "result = attn_model.evaluate(x_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dgkH5WNJv-kt"
   },
   "source": [
    "### Bidirectional LSTM Classifier with attention and GloVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6xfUbHSFo75J",
    "outputId": "120cb850-944d-4767-8631-d4f66f80600d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('./drive/My Drive/W266/', 'glove.6B.50d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1BT-Ln2C0GY1",
    "outputId": "fdd99593-e7d4-4a50-b290-bd5a41ecc86e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 73129 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9riqdJ60IxI"
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/hamishdickson/bidirectional-lstm-in-keras-with-glove-embeddings \n",
    "\n",
    "vocab_size = len(word_index) + 1\n",
    "\n",
    "embedding_dim = 50\n",
    "\n",
    "\n",
    "# first create a matrix of zeros, this is our embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "# for each word in out tokenizer lets try to find that work in our w2v model\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # we found the word - add that words vector to the matrix\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        # doesn't exist, assign a random vector\n",
    "        embedding_matrix[i] = np.random.randn(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "Gljs7Upx1p6u",
    "outputId": "de76b366-3c4c-4a20-cbdf-98cc57a723c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 500)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_layer (Embedding)  (None, 500, 50)           3656500   \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  [(None, 500, 256), (None, 314368    \n",
      "_________________________________________________________________\n",
      "Attention (BahdanauAttention ((None, 256), (None, 500, 65921     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 4,037,046\n",
      "Trainable params: 4,037,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "attn_units=128\n",
    "sequence_input = layers.Input(shape=(max_len,),name=\"input_layer\", dtype='int32')\n",
    "#put in glove embeddings in weights\n",
    "embeddings = keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_units, input_length=max_len, weights=[embedding_matrix], name=\"embedding_layer\")(sequence_input)\n",
    "lstm_output,hidden_h, hidden_c=tf.keras.layers.LSTM(rnn_units,name='LSTM',return_sequences=True,\n",
    "                                      return_state=True)(embeddings)\n",
    "context_vector, attention_weights = BahdanauAttention(attn_units)(lstm_output, hidden_h)\n",
    "output = keras.layers.Dense(1, activation='sigmoid',name='output_layer')(context_vector)\n",
    "glove_attn_model = keras.Model(inputs=sequence_input, outputs=output)\n",
    " \n",
    "# summarize layers\n",
    "glove_attn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYdzhcO4FHYv"
   },
   "outputs": [],
   "source": [
    "glove_attn_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                        min_delta=0,\n",
    "                                                        patience=3,\n",
    "                                                        verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "O_tR9j84GDMD",
    "outputId": "8293aa66-90dd-4c84-f7b3-7e721520a16d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "569/569 [==============================] - 96s 169ms/step - loss: 0.6402 - accuracy: 0.6398 - val_loss: 0.6307 - val_accuracy: 0.6526\n",
      "Epoch 2/2\n",
      "569/569 [==============================] - 96s 168ms/step - loss: 0.6282 - accuracy: 0.6512 - val_loss: 0.6295 - val_accuracy: 0.6543\n"
     ]
    }
   ],
   "source": [
    "history = glove_attn_model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=2,\n",
    "                    batch_size=200,\n",
    "                    validation_split=.3, verbose=1, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "2AZTY0XXGFKr",
    "outputId": "817bead8-021b-464c-c0b1-0b639cc30a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270/1270 [==============================] - 18s 14ms/step - loss: 0.6309 - accuracy: 0.6519\n",
      "[0.6308534145355225, 0.651942789554596]\n"
     ]
    }
   ],
   "source": [
    "result = glove_attn_model.evaluate(x_test, y_test)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Yelp_LSTM_Suzy_asian.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

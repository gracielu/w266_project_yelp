{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YelpBert",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ec3db891dff4fc793e6ad9a9c5dc2cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f72a8d86ee234686bd8200dd765a133a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e7b9063c744b41eea3694813cf5b51ed",
              "IPY_MODEL_0744a71f015646d99850e7146f030dab"
            ]
          }
        },
        "f72a8d86ee234686bd8200dd765a133a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7b9063c744b41eea3694813cf5b51ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_797b511d98c8415c83ddfddaa357931a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b80136fd24224ef384c01f7b2d884d93"
          }
        },
        "0744a71f015646d99850e7146f030dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5345ea4d67634855a58a4434c97ad855",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 551kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe640fbffbcd4f52ae39c06aee2c5268"
          }
        },
        "797b511d98c8415c83ddfddaa357931a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b80136fd24224ef384c01f7b2d884d93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5345ea4d67634855a58a4434c97ad855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe640fbffbcd4f52ae39c06aee2c5268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhWG79ymv6Hl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fe8bc42-e9b1-4270-b7f5-a9f758ae6dee"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YEvEzWjxQXR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "169d2dd7-68ed-4161-90c0-2006975319bb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/contents/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /contents/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzn7CE9xxd56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMza4a76xYvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yelp_reviews=pd.read_csv(\"/contents/My Drive/review_data_mexican.csv\")"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxyi_oyB2W2X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "857ddd0d-8a15-46af-87ad-5d4bfba1b36b"
      },
      "source": [
        "yelp_reviews.head()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cuisine</th>\n",
              "      <th>useful</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mexican</td>\n",
              "      <td>0</td>\n",
              "      <td>Great basics. Beans are made right. Tortillas ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mexican</td>\n",
              "      <td>0</td>\n",
              "      <td>Automatic star awarded for having a salsa bar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mexican</td>\n",
              "      <td>0</td>\n",
              "      <td>Got the #7 Enchilada and Burrito great food an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mexican</td>\n",
              "      <td>0</td>\n",
              "      <td>good food for the price. I like their new loca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mexican</td>\n",
              "      <td>1</td>\n",
              "      <td>One of the better breakfast burritos I have ha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cuisine  useful                                               text\n",
              "0  Mexican       0  Great basics. Beans are made right. Tortillas ...\n",
              "1  Mexican       0  Automatic star awarded for having a salsa bar ...\n",
              "2  Mexican       0  Got the #7 Enchilada and Burrito great food an...\n",
              "3  Mexican       0  good food for the price. I like their new loca...\n",
              "4  Mexican       1  One of the better breakfast burritos I have ha..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWNfRie-2dsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yelp_reviews[\"labels\"]= yelp_reviews[\"useful\"].apply(lambda x: 1 if x >= 1  else 0)\n",
        "\n",
        "#yelp_reviews[\"labels\"]= yelp_reviews[\"stars\"].apply(lambda x: 1 if x > 3  else 0)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61lQcweb2jL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = yelp_reviews.loc[:5000, \"text\"]\n",
        "labels = yelp_reviews.loc[:5000, \"labels\"]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGaMFD1Q4C8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7b99b16e-58e2-43b7-fbf5-4db58db105af"
      },
      "source": [
        "texts[0:6]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Great basics. Beans are made right. Tortillas ...\n",
              "1    Automatic star awarded for having a salsa bar ...\n",
              "2    Got the #7 Enchilada and Burrito great food an...\n",
              "3    good food for the price. I like their new loca...\n",
              "4    One of the better breakfast burritos I have ha...\n",
              "5    Amado's Bros is a new favorite Friday breakfas...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bwXtqul4LsU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3734b1a3-0a6c-435f-8681-728bc213ef75"
      },
      "source": [
        "labels[0:6]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    1\n",
              "5    0\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJzc-mBK1fqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length = 128 #512\n",
        "batch_size = 6\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGF62cCmw-5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "e994c9ef-cc12-44db-ad30-02762d6231dc"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 22.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 49.4MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 29.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=320d10478d5f87a7f04a80975d06434f0da5bcbdf685f7e9d1ec6352f2c1a7ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE22PsHMxIm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "5ec3db891dff4fc793e6ad9a9c5dc2cc",
            "f72a8d86ee234686bd8200dd765a133a",
            "e7b9063c744b41eea3694813cf5b51ed",
            "0744a71f015646d99850e7146f030dab",
            "797b511d98c8415c83ddfddaa357931a",
            "b80136fd24224ef384c01f7b2d884d93",
            "5345ea4d67634855a58a4434c97ad855",
            "fe640fbffbcd4f52ae39c06aee2c5268"
          ]
        },
        "outputId": "6e1a5bf8-e4f1-43eb-b35a-3b6113c01780"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ec3db891dff4fc793e6ad9a9c5dc2cc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r0xOeA2gTD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d2U-mXx2uiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_example_to_feature(review):\n",
        "  \n",
        "  # combine step for tokenization, WordPiece vector mapping, adding special tokens as well as truncating reviews longer than the max length\n",
        "  \n",
        "  return tokenizer.encode_plus(review, \n",
        "                add_special_tokens = True, # add [CLS], [SEP]\n",
        "                max_length = max_length, # max length of the text that can go to BERT\n",
        "                pad_to_max_length = True, # add [PAD] tokens\n",
        "                return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
        "                truncation=True\n",
        "              )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_IwTcle7URu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ddd60616-e774-4dfa-99e2-2f47c5fdc8df"
      },
      "source": [
        "convert_example_to_feature(\"this is just a test\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2023, 2003, 2074, 1037, 3231, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NfaXQKQkr2X",
        "colab_type": "text"
      },
      "source": [
        "### Create x_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7N0cB9pU7zA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_examples(texts):\n",
        "\n",
        "  # prepare list, so that we can build up final TensorFlow dataset from slices.\n",
        "    input_ids_list = []\n",
        "    token_type_ids_list = []\n",
        "    attention_mask_list = []\n",
        "    label_list = []\n",
        "    \n",
        "    for review in texts:\n",
        "\n",
        "        bert_input = convert_example_to_feature(review)\n",
        "\n",
        "        input_ids_list.append(bert_input['input_ids'])\n",
        "        token_type_ids_list.append(bert_input['token_type_ids'])\n",
        "        attention_mask_list.append(bert_input['attention_mask'])\n",
        "        \n",
        "        bert_inputs = np.array([input_ids_list, attention_mask_list, token_type_ids_list])\n",
        "        \n",
        "\n",
        "    #return map_example_to_dict(input_ids_list, attention_mask_list, token_type_ids_list)\n",
        "    return bert_inputs\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8w5qHnknil-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_1 = encode_examples(texts)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKcvN8n4kUFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a88926d6-10cc-4705-d474-9c4f5a8c5269"
      },
      "source": [
        "x_train_1.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 5001, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2wT0vfokYZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6cdaed30-a0ce-4121-85d8-a778fe8220a4"
      },
      "source": [
        "x_train_1[0].shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5001, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBuP1CUykc-f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "a823aa91-6bd7-4b87-b095-ed983f910f6e"
      },
      "source": [
        "x_train_1[0][0:3]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  101,  2307, 24078,  1012, 13435,  2024,  2081,  2157,  1012,\n",
              "        17153, 28345,  3022,  2024,  5171,  1012,  2021,  1996, 26929,\n",
              "         2113,  2054,  2027,  2024,  2725,  1998,  1996, 12901,  2015,\n",
              "         2024,  2682,  3671,  1012,  2123,  1005,  1056,  2022,  6015,\n",
              "         2065,  2017,  2123,  1005,  1056,  3713,  2394,  2021,  4209,\n",
              "         1037,  2210,  3009,  3084,  1996,  3325,  2488,  1012,  2065,\n",
              "         1057,  2444,  2182,  1057,  2323,  3713,  3009,  4312,  2015,\n",
              "         1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [  101,  6882,  2732,  3018,  2005,  2383,  1037, 26509,  3347,\n",
              "         1998,  1037,  4365,  2204,  2028,  2012,  2008,  1012,  6583,\n",
              "         9905,  2015,  2020,  2204,  1010,  2021,  1996,  8808,  2347,\n",
              "         1005,  1056, 12501,  1010,  2029,  1010,  1045,  2097,  2196,\n",
              "        17612,  2055,  8808,  1999,  2151,  2433,  1010,  2021,  2023,\n",
              "         2001,  1037,  2978,  2367,  2059,  2054,  1045,  2572,  2224,\n",
              "         2000,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [  101,  2288,  1996,  1001,  1021,  4372,  5428, 27266,  2050,\n",
              "         1998, 22715,  9956,  2307,  2833,  1998,  2307,  3976,  1012,\n",
              "         2564,  2288, 12183,  3527,  2056,  2009,  2001,  7929,  2021,\n",
              "         1045,  2228, 12183,  3527,  2003, 19424,  4312,  2015,  1012,\n",
              "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXl7Lb5qukxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_train_1 = [x_train_1[0], x_train_1[1], x_train_1[2]]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlhC8dimkwqb",
        "colab_type": "text"
      },
      "source": [
        "### Create y_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C97qBsA_ZQgP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cbe385c-fa53-4418-9beb-c902231947d6"
      },
      "source": [
        "labels.shape[0]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZCp-LPDexZA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d97d2361-1e51-44e0-daf5-9ec548fc4ad5"
      },
      "source": [
        "y_train_1 = np.array(labels)\n",
        "y_train_1.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5001,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POlkrwl_zJqT",
        "colab_type": "text"
      },
      "source": [
        "### Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_wlVQkZz5dV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bc2df7f-2f88-4968-dcd4-f3b841c761f0"
      },
      "source": [
        "len(x_train_1[0])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxlLJrDGyyek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numSentences = len(x_train_1[0])\n",
        "np.random.seed(0)\n",
        "training_examples = np.random.binomial(1, 0.7, numSentences)\n",
        "\n",
        "trainSentence_ids = []\n",
        "trainMasks = []\n",
        "trainSequence_ids = []\n",
        "\n",
        "testSentence_ids = []\n",
        "testMasks = []\n",
        "testSequence_ids = []\n",
        "\n",
        "Labels_train =[]\n",
        "Labels_test = []\n",
        "\n",
        "\n",
        "for example in range(numSentences):\n",
        "    if training_examples[example] == 1:\n",
        "        trainSentence_ids.append(x_train_1[0][example])\n",
        "        trainMasks.append(x_train_1[1][example])\n",
        "        trainSequence_ids.append(x_train_1[2][example])\n",
        "        Labels_train.append(y_train_1[example])\n",
        "    else:\n",
        "        testSentence_ids.append(x_train_1[0][example])\n",
        "        testMasks.append(x_train_1[1][example])\n",
        "        testSequence_ids.append(x_train_1[2][example])\n",
        "        Labels_test.append(y_train_1[example])\n",
        "        \n",
        "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
        "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
        "\n",
        "y_train = np.array(Labels_train)\n",
        "y_test = np.array(Labels_test)\n",
        "\n",
        "X_train = [X_train[0], X_train[1], X_train[2]]\n",
        "X_test = [X_test[0], X_test[1], X_test[2]]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWxr25rVmFl7",
        "colab_type": "text"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdcdZwLArJFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import TFBertModel"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkODmdicmM6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classifier_model(max_input_length, train_layers, optimizer):\n",
        "    \"\"\"\n",
        "    Implementation of NER model\n",
        "    \n",
        "    variables:\n",
        "        max_input_length: number of tokens (max_length + 1)\n",
        "        train_layers: number of layers to be retrained\n",
        "        optimizer: optimizer to be used\n",
        "    \n",
        "    returns: model\n",
        "    \"\"\"\n",
        "    \n",
        "    in_id = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_ids\")\n",
        "    in_mask = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_masks\")\n",
        "    in_segment = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"segment_ids\")\n",
        "    \n",
        "    \n",
        "    bert_inputs = [in_id, in_mask, in_segment]\n",
        "       \n",
        "    # Note: Bert layer from Hugging Face returns two values: sequence ouput, and pooled output. Here, we only want\n",
        "    # the former. (See https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel) \n",
        "    \n",
        "    bert_layer = TFBertModel.from_pretrained('bert-base-cased')\n",
        "    \n",
        "    # Freeze layers, i.e. only train number of layers specified, starting from the top\n",
        "    \n",
        "    retrain_layers = []\n",
        "    \n",
        "    for retrain_layer_number in range(train_layers):\n",
        "        \n",
        "        layer_code = '_' + str(11 - retrain_layer_number)\n",
        "        retrain_layers.append(layer_code)\n",
        "    \n",
        "    for w in bert_layer.weights:\n",
        "        if not any([x in w.name for x in retrain_layers]):\n",
        "            w._trainable = False\n",
        "            \n",
        "    # End of freezing section\n",
        "    \n",
        "    bert_sequence = bert_layer(bert_inputs)[0]\n",
        "    \n",
        "    print('Let us check the shape of the BERT layer output:', bert_sequence)\n",
        "    \n",
        "    dense = tf.keras.layers.Dense(256, activation='relu', name='dense')(bert_sequence)\n",
        "    \n",
        "    dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
        "    \n",
        "    pred = tf.keras.layers.Dense(1, activation='softmax', name='classifier')(dense)\n",
        "     # sigmoid\n",
        "    print('pred: ', pred)\n",
        "    \n",
        "    ## Prepare for multipe loss functions, although not used here\n",
        "      \n",
        "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "       \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8sHeTCboFRM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "0151fe92-888f-43f5-e84d-261c820797df"
      },
      "source": [
        "X_train[0][0]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101,  2307, 24078,  1012, 13435,  2024,  2081,  2157,  1012,\n",
              "       17153, 28345,  3022,  2024,  5171,  1012,  2021,  1996, 26929,\n",
              "        2113,  2054,  2027,  2024,  2725,  1998,  1996, 12901,  2015,\n",
              "        2024,  2682,  3671,  1012,  2123,  1005,  1056,  2022,  6015,\n",
              "        2065,  2017,  2123,  1005,  1056,  3713,  2394,  2021,  4209,\n",
              "        1037,  2210,  3009,  3084,  1996,  3325,  2488,  1012,  2065,\n",
              "        1057,  2444,  2182,  1057,  2323,  3713,  3009,  4312,  2015,\n",
              "        1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzP2J6esmf5V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "e02f9e1c-dc0c-494d-8d36-541388b9ca84"
      },
      "source": [
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "model = classifier_model(max_length + 1, train_layers=0, optimizer = 'adam')\n",
        "\n",
        "model.fit(\n",
        "    X_train, \n",
        "    y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=2,\n",
        "    batch_size=16\n",
        ")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Let us check the shape of the BERT layer output: Tensor(\"tf_bert_model_3/Identity:0\", shape=(None, 128, 768), dtype=float32)\n",
            "pred:  Tensor(\"classifier_3/Identity:0\", shape=(None, 128, 1), dtype=float32)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_3 (TFBertModel)   ((None, 128, 768), ( 108310272   input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128, 256)     196864      tf_bert_model_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_227 (Dropout)           (None, 128, 256)     0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (None, 128, 1)       257         dropout_227[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 108,507,393\n",
            "Trainable params: 108,507,393\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/2\n",
            "220/220 [==============================] - 66s 300ms/step - loss: 8.7194 - accuracy: 0.4282 - val_loss: 9.2071 - val_accuracy: 0.3962\n",
            "Epoch 2/2\n",
            "220/220 [==============================] - 63s 288ms/step - loss: 8.7194 - accuracy: 0.4282 - val_loss: 9.2071 - val_accuracy: 0.3962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f683db1b0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0-2AmZN1PLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "0e474e1b-c416-44fc-9e3f-aba3857c74e8"
      },
      "source": [
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "model = classifier_model(max_length + 1, train_layers=1, optimizer = 'adam')\n",
        "\n",
        "model.fit(\n",
        "    X_train, \n",
        "    y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=2,\n",
        "    batch_size=16\n",
        ")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Let us check the shape of the BERT layer output: Tensor(\"tf_bert_model_4/Identity:0\", shape=(None, 128, 768), dtype=float32)\n",
            "pred:  Tensor(\"classifier_4/Identity:0\", shape=(None, 128, 1), dtype=float32)\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_4 (TFBertModel)   ((None, 128, 768), ( 108310272   input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128, 256)     196864      tf_bert_model_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_265 (Dropout)           (None, 128, 256)     0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (None, 128, 1)       257         dropout_265[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 108,507,393\n",
            "Trainable params: 108,507,393\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/2\n",
            "220/220 [==============================] - 71s 324ms/step - loss: 8.7194 - accuracy: 0.4282 - val_loss: 9.2071 - val_accuracy: 0.3962\n",
            "Epoch 2/2\n",
            "220/220 [==============================] - 69s 312ms/step - loss: 8.7194 - accuracy: 0.4282 - val_loss: 9.2071 - val_accuracy: 0.3962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f68356f21d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY0DsRz1n5lF",
        "colab_type": "text"
      },
      "source": [
        "## TFBertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZmDXJen8mX3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "678754af-c8b2-4cee-dfef-fe48724026e2"
      },
      "source": [
        "from transformers import TFBertForSequenceClassification\n",
        "import tensorflow as tf\n",
        "\n",
        "# recommended learning rate for Adam 5e-5, 3e-5, 2e-5\n",
        "learning_rate = 2e-5\n",
        "\n",
        "# we will do just 1 epoch for illustration, though multiple epochs might be better as long as we will not overfit the model\n",
        "number_of_epochs = 1\n",
        "\n",
        "\n",
        "# model initialization\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# choosing Adam optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
        "\n",
        "# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertForSequenceClassification: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier', 'dropout_189']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmtN3Vcg81g8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5b2bf92c-819c-4205-a3c9-d5b46f4aa1f7"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=number_of_epochs)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 56s 512ms/step - loss: 8.7194 - accuracy: 0.4282 - val_loss: 9.2071 - val_accuracy: 0.3962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f683bfb9eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgH0pDe010du",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "fe7abb63-e00b-48dd-a8e5-fe0593eb0b2e"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "110/110 [==============================] - 56s 512ms/step - loss: 8.7194 - accuracy: 0.4282 - val_loss: 9.2071 - val_accuracy: 0.3962\n",
            "Epoch 2/3\n",
            "110/110 [==============================] - 56s 513ms/step - loss: 8.7194 - accuracy: 0.4282 - val_loss: 9.2071 - val_accuracy: 0.3962\n",
            "Epoch 3/3\n",
            "110/110 [==============================] - 56s 513ms/step - loss: 8.7194 - accuracy: 0.4282 - val_loss: 9.2071 - val_accuracy: 0.3962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6837887710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    }
  ]
}